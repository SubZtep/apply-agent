# apply-agent wip

Self-hosted job scraper runner with self-hosted LLM-powered CV matching.

‚ö†Ô∏è It‚Äôs possible to filter out legitimate jobs, so use it with caution.

## What‚Äôs happening

Helps you find jobs to apply for. üë∑üí≠

### Folder structure

Every job is a _markdown_ file. During the evaluation process, it gets updated with notes and travels between status folders. No database required.

Here is the folder sctructure for `./[job].md` files for further process structure:

```
data/jobs/
     ‚îú‚îÄ‚îÄ inbox/             # raw scraped jobs (unscored)
     ‚îú‚îÄ‚îÄ screened_out/      # rejected by batch scoring
     ‚îú‚îÄ‚îÄ shortlisted/       # passed batch scoring
     ‚îú‚îÄ‚îÄ awaiting_input/    # agent needs human input
     ‚îú‚îÄ‚îÄ declined/          # rejected by agent reasoning
     ‚îî‚îÄ‚îÄ approved/          # agent-approved jobs
```

### What‚Äôs **automatised**

| Get jobs                       | Filter the noise out                 | Challenge a job            |
| ------------------------------ | ------------------------------------ | -------------------------- |
| 1Ô∏è‚É£ Visit a jobsite              | 1Ô∏è‚É£ Get a jobs CSV from **inbox**      | Agent compare with yout CV |
| 2Ô∏è‚É£ Search jobs by criteria      | 2Ô∏è‚É£ Run batch scoring with a light LLM |                            |
| 3Ô∏è‚É£ Download as CSV to **inbox** | üëé Unrealistic to **screened_out**    |                            |
|                                | üëç Good ones to **shortlisted**       |                            |


> Batch reject:\
> _‚Äú**Not worth thinking **about****‚Äù_
> 
> Agent reject:\
> _‚Äú**Thought about it carefully and decided no**‚Äù_

## Run without Docker

This is the hard way, the best for low-level machines. If you're not a developer, probably need to install required dependencies on your machine.

### Requirements

- **Linux**/_Mac_/~~_Windows_~~

  (WSL welcome)

- **Bun JavaScript**

  [Install](https://bun.com/docs/installation#installation) the latest(?) version.
  Node.js is not supported.

- **Python**
  
  Need version 3.10+.
  Runs the 3rd-party [scraper](https://github.com/speedyapply/JobSpy).

- **LM Studio**

  Recommended to increase model‚Äôs default context window to 8192.

  Default (required) models:
  - qwen/qwen3-4b-2507
  - qwen3-0.6b-mlx

### Custom configuration

The predefined LLM API _base URL_ is expecting a local running [LM Studio](https://lmstudio.ai/), with the loadable models. The default models are CPU friendly, selected for bare minimum setup, but the result can be better.

Actually any [Open AI **compatible**](https://www.npmjs.com/package/@ai-sdk/openai-compatible) host should work, with any LLM models. Change the default configutation to discover.

Create `.env.local` with any of these lines:

```ini
AI_API_BASE_URL=[open ai api endpoint]
AGENT_MODEL=[strong model for agentic run]
BATCH_MODEL=[light model for intanse run]
```

### Installation

First of all, clone the project.

Install JavaScript dependencies:

```bash
bun install
```

The post-install script validates config and install other requirements.

Create the `data/cv.md` file with your data.

### Retrieve fresh jobs

Scrape the configured search on selected job boards and for new listings.

```bash
./tools/scrape.sh
```

It creates the jobs CSV in the `data/jobs/inbox` folder.

### Run batch scorer

Quickly filter out the obvious no-gos.

```bash
bun run score_batch
```

It moves the possible jobs to the `data/jobs/shortlisted` folder, and the others to the `data/jobs/screened_out` one.

### Run the agent

```bash
bun start run
```

If the agens is ambiguous about a job post, it will set some questions and move the job to the `data/jobs/awaiting_input` folder. Answer questions to resolve ambiguous job posts.

The id parameter will be the output of the _run_ script. Use `--force-proceed` to auto-accept the answers to approve.

```bash
bun start resume <id> [--force-proceed]
```

Move the potential jobs to `data/jobs/approved`, and the less interesting ones to `data/jobs/declined`.

## Etc.

### Data flow

```
[ Python scraper ]
        ‚Üì
  (job records)
        ‚Üì
[ job inbox (files) ]
        ‚Üì
[ batch scorer ]
        ‚Üì
[ ranked jobs ]
        ‚Üì
[ agent runs ]
```

### Agent states

```
IDLE
  ‚Üì
INGEST
  ‚Üì
NORMALIZE
  ‚Üì
EVALUATE
  ‚Üì
CHALLENGE
  ‚Üì
DECIDE <‚îÄ‚îÄ‚îÄ> WAIT_FOR_HUMAN
  ‚Üì               |
 PLAN             |
  ‚Üì               ‚Üì
 DONE            ERROR
```

### Mode semantics

The agent runs in strict mode by default. Add the parameter __**x**__ ‚Äî `bun start run x` ‚Äî to start in exploratory mode (no questions).

| Strict                                       | Exploratory                               |
| -------------------------------------------- | ----------------------------------------- |
| Any unresolved uncertainty ‚Üí WAIT_FOR_HUMAN  | Hard gaps ‚Üí ask once, then proceed        |
| Hard gaps ‚Üí WAIT_FOR_HUMAN                   | Low confidence ‚Üí assume best-case         |
| Low confidence ‚Üí WAIT_FOR_HUMAN              | LOW_QUALITY ‚Üí downgrade severity, proceed |
| LOW_QUALITY from EVALUATE/CHALLENGE ‚Üí FAILED | Bias toward PLAN                          |
